{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charan6924/Deep-Learning/blob/main/SuperResolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7agrA1uzrV44"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import gc\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I03cIMr0GfQs"
      },
      "outputs": [],
      "source": [
        "all_files = [\n",
        "    '/content/data/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272_LR.parquet',\n",
        "    '/content/data/QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540_LR.parquet',\n",
        "    '/content/data/QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494_LR.parquet',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Vht-eyxOXGn3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset, get_worker_info\n",
        "import pyarrow.parquet as pq\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class JetImageDataset(IterableDataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        parquet_files,\n",
        "        split=\"train\",\n",
        "        train_ratio=0.8,\n",
        "        chunk_size=512,\n",
        "        normalize=True,\n",
        "        seed=42,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.parquet_files = parquet_files\n",
        "        self.split = split\n",
        "        self.train_ratio = train_ratio\n",
        "        self.chunk_size = chunk_size\n",
        "        self.normalize = normalize\n",
        "        self.seed = seed\n",
        "\n",
        "        self.lr_col = \"X_jets_LR\"\n",
        "        self.hr_col = \"X_jets\"\n",
        "\n",
        "        self.lr_shape = (3, 64, 64)\n",
        "        self.hr_shape = (3, 125, 125)\n",
        "\n",
        "        assert split in {\"train\", \"val\"}\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Worker-aware file sharding\n",
        "    # ---------------------------------------------------\n",
        "    def _get_worker_files(self):\n",
        "        worker = get_worker_info()\n",
        "        if worker is None:\n",
        "            return self.parquet_files\n",
        "        return self.parquet_files[worker.id :: worker.num_workers]\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Vectorized chunk conversion (FAST)\n",
        "    # ---------------------------------------------------\n",
        "    def _convert_chunk(self, batch):\n",
        "      lr_col = batch.column(self.lr_col).to_numpy(zero_copy_only=False)\n",
        "      hr_col = batch.column(self.hr_col).to_numpy(zero_copy_only=False)\n",
        "\n",
        "      lr_out = np.empty((len(lr_col), 3, 64, 64), dtype=np.float32)\n",
        "      hr_out = np.empty((len(hr_col), 3, 125, 125), dtype=np.float32)\n",
        "\n",
        "      for i in range(len(lr_col)):\n",
        "          # LR\n",
        "          for c in range(3):\n",
        "              lr_out[i, c] = np.stack(lr_col[i][c], axis=0)\n",
        "\n",
        "          # HR\n",
        "          for c in range(3):\n",
        "              hr_out[i, c] = np.stack(hr_col[i][c], axis=0)\n",
        "\n",
        "      lr = torch.from_numpy(lr_out)\n",
        "      hr = torch.from_numpy(hr_out)\n",
        "\n",
        "      if self.normalize:\n",
        "          lr /= 255.0\n",
        "          hr /= 255.0\n",
        "\n",
        "      return lr, hr\n",
        "\n",
        "\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Main iterator\n",
        "    # ---------------------------------------------------\n",
        "    def __iter__(self):\n",
        "        rng = np.random.default_rng(self.seed)\n",
        "        files = self._get_worker_files()\n",
        "\n",
        "        for file_path in files:\n",
        "            parquet = pq.ParquetFile(file_path)\n",
        "\n",
        "            for batch in parquet.iter_batches(\n",
        "                batch_size=self.chunk_size,\n",
        "                columns=[self.lr_col, self.hr_col],\n",
        "            ):\n",
        "                lr, hr = self._convert_chunk(batch)\n",
        "\n",
        "                # Deterministic train/val split per chunk\n",
        "                mask = rng.random(len(lr)) < self.train_ratio\n",
        "                if self.split == \"train\":\n",
        "                    idxs = torch.where(torch.from_numpy(mask))[0]\n",
        "                else:\n",
        "                    idxs = torch.where(torch.from_numpy(~mask))[0]\n",
        "\n",
        "                for i in idxs:\n",
        "                    yield lr[i], hr[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "for i, (lr, hr) in enumerate(train_dataset):\n",
        "    if i == 100:\n",
        "        break\n",
        "print(\"100 batches took:\", time.time() - t0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMwQEOwsCo3s",
        "outputId": "8d056497-de98-408c-e3e1-e8e6a2ff921e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 batches took: 1.6113498210906982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G9-XM3fWZNzz"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    lr_batch = torch.stack([item[0] for item in batch])\n",
        "    hr_batch = torch.stack([item[1] for item in batch])\n",
        "    return lr_batch, hr_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KqGfv61FXhpx"
      },
      "outputs": [],
      "source": [
        "train_dataset = JetImageDataset(\n",
        "    parquet_files=all_files,\n",
        "    split='train',\n",
        "    train_ratio=0.8,\n",
        "    chunk_size=512,\n",
        "    normalize=False\n",
        ")\n",
        "\n",
        "val_dataset = JetImageDataset(\n",
        "    parquet_files=all_files,\n",
        "    split='val',\n",
        "    train_ratio=0.8,\n",
        "    chunk_size=512,\n",
        "    normalize=False\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=4, pin_memory=True,prefetch_factor = 2,persistent_workers=True,  )\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, num_workers=4, pin_memory=True, prefetch_factor = 2,persistent_workers=True,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAmmsvOW1vFj",
        "outputId": "c82b16c5-5333-430b-8307-406e8bc72b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TESTING FIXED DATALOADERS\n",
            "============================================================\n",
            "\n",
            "1. Testing train loader...\n",
            "   âœ“ Batch 0: LR torch.Size([32, 3, 64, 64]), HR torch.Size([32, 3, 125, 125])\n",
            "   âœ“ LR range: [-0.3349, 25.7476]\n",
            "   âœ“ HR range: [-0.7979, 99.7956]\n",
            "   âœ“ Batch 1: LR torch.Size([32, 3, 64, 64]), HR torch.Size([32, 3, 125, 125])\n",
            "   âœ“ LR range: [-0.4713, 27.1652]\n",
            "   âœ“ HR range: [-1.0997, 108.6606]\n",
            "   âœ“ Batch 2: LR torch.Size([32, 3, 64, 64]), HR torch.Size([32, 3, 125, 125])\n",
            "   âœ“ LR range: [-0.1532, 23.7911]\n",
            "   âœ“ HR range: [-0.6128, 95.1645]\n",
            "\n",
            "2. Testing val loader...\n",
            "   âœ“ Batch 0: LR torch.Size([32, 3, 64, 64]), HR torch.Size([32, 3, 125, 125])\n",
            "   âœ“ Batch 1: LR torch.Size([32, 3, 64, 64]), HR torch.Size([32, 3, 125, 125])\n",
            "\n",
            "============================================================\n",
            "âœ“âœ“âœ“ ALL TESTS PASSED! âœ“âœ“âœ“\n",
            "============================================================\n",
            "\n",
            "ðŸŽ‰ Dataloaders are working correctly!\n",
            "ðŸš€ Ready to train!\n",
            "\n",
            "============================================================\n",
            "NEXT: RUN YOUR TRAINING LOOP\n",
            "============================================================\n",
            "\n",
            "The ZeroDivisionError is fixed!\n",
            "All 111K+ samples will now load correctly.\n"
          ]
        }
      ],
      "source": [
        "def test_fixed_dataloaders():\n",
        "    \"\"\"Test the fixed dataloaders.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TESTING FIXED DATALOADERS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        print(\"\\n1. Testing train loader...\")\n",
        "        for i, (lr, hr) in enumerate(train_loader):\n",
        "            print(f\"   âœ“ Batch {i}: LR {lr.shape}, HR {hr.shape}\")\n",
        "            print(f\"   âœ“ LR range: [{lr.min():.4f}, {lr.max():.4f}]\")\n",
        "            print(f\"   âœ“ HR range: [{hr.min():.4f}, {hr.max():.4f}]\")\n",
        "\n",
        "            if i >= 2:\n",
        "                break\n",
        "\n",
        "        print(\"\\n2. Testing val loader...\")\n",
        "        for i, (lr, hr) in enumerate(val_loader):\n",
        "            print(f\"   âœ“ Batch {i}: LR {lr.shape}, HR {hr.shape}\")\n",
        "\n",
        "            if i >= 1:\n",
        "                break\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"âœ“âœ“âœ“ ALL TESTS PASSED! âœ“âœ“âœ“\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"\\nðŸŽ‰ Dataloaders are working correctly!\")\n",
        "        print(\"ðŸš€ Ready to train!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "\n",
        "# RUN THE TEST\n",
        "if __name__ == \"__main__\":\n",
        "    test_passed = test_fixed_dataloaders()\n",
        "\n",
        "    if test_passed:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"NEXT: RUN YOUR TRAINING LOOP\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"\\nThe ZeroDivisionError is fixed!\")\n",
        "        print(\"All 111K+ samples will now load correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "noOrR1hLBuCs"
      },
      "outputs": [],
      "source": [
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, scale_factor=2):\n",
        "        super(UpsampleBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels * (scale_factor ** 2),\n",
        "                             kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4tGUSvavpEde"
      },
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // reduction, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention = self.avg_pool(x)\n",
        "        attention = self.fc(attention)\n",
        "        return x * attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JZ88PMhBpcqs"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self,channels):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.prelu = nn.PReLU(num_parameters=channels)\n",
        "    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "  def forward(self,x):\n",
        "    residual = self.conv1(x)\n",
        "    residual = self.bn1(residual)\n",
        "    residual = self.prelu(residual)\n",
        "    residual = self.conv2(residual)\n",
        "    residual = self.bn2(residual)\n",
        "    return x + 0.1 * residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "GRbOAyfNIcPL"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, resblocks=16, channels=3, base_channels=64, use_attention=True):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv_input = nn.Sequential(\n",
        "            nn.Conv2d(channels, base_channels, kernel_size=9, padding=4),\n",
        "            nn.PReLU())\n",
        "        res_blocks = []\n",
        "        for i in range(resblocks):\n",
        "            res_blocks.append(ResBlock(base_channels))\n",
        "            if use_attention and i in {7, 15}:  # only 2 attention\n",
        "              res_blocks.append(ChannelAttention(base_channels))\n",
        "\n",
        "        self.resblocks = nn.Sequential(*res_blocks)\n",
        "        self.conv_mid = nn.Sequential(\n",
        "            nn.Conv2d(base_channels, base_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(base_channels)\n",
        "        )\n",
        "        self.upsample1 = UpsampleBlock(base_channels, base_channels)  # 64â†’128\n",
        "        self.conv_output = nn.Sequential(\n",
        "            nn.Conv2d(base_channels, base_channels, kernel_size=3, padding=1),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(base_channels, channels, kernel_size=9, padding=4)\n",
        "        )\n",
        "        self.final_resize = nn.Upsample(size=(125, 125), mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv_input(x)\n",
        "        x2 = self.resblocks(x1)\n",
        "        x3 = self.conv_mid(x2)\n",
        "        x_mid = x1 + x3\n",
        "        x_up = self.upsample1(x_mid)\n",
        "        out = self.conv_output(x_up)\n",
        "        out = self.final_resize(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mKbZouuGJHPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac825b4e-1576-4c74-88ca-08e47f0b5427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1759218625.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "model = Generator().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "criterion = nn.MSELoss()\n",
        "model.train()\n",
        "EPOCHS = 20\n",
        "PATIENCE = 3\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "train_lossi = []\n",
        "val_lossi = []\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mbBZuGWcQfcU",
        "outputId": "93ce9e26-8055-4437-d71b-9859aa873859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3487076461.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Ep 1 | Step 0 | Train Loss: 0.060442\n",
            "   Ep 1 | Step 500 | Train Loss: 0.030239\n",
            "   Ep 1 | Step 1000 | Train Loss: 0.034384\n",
            "   Ep 1 | Step 1500 | Train Loss: 0.038581\n",
            "   Ep 1 | Step 2000 | Train Loss: 0.029179\n",
            "   Ep 1 | Step 2500 | Train Loss: 0.031284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3487076461.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Ep 1 | Step 3000 | Train Loss: 0.026454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3487076461.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Summary: Train Loss: 1.395247 | Val Loss: 0.141900 | Time: 393.0s\n",
            "IMPROVEMENT! (inf -> 0.141900)\n",
            "Saved Best Model to /content/sr_model_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3487076461.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Ep 2 | Step 0 | Train Loss: 0.033592\n",
            "   Ep 2 | Step 500 | Train Loss: 0.029358\n",
            "   Ep 2 | Step 1000 | Train Loss: 0.033238\n",
            "   Ep 2 | Step 1500 | Train Loss: 0.036452\n",
            "   Ep 2 | Step 2000 | Train Loss: 0.028755\n",
            "   Ep 2 | Step 2500 | Train Loss: 0.030107\n",
            "   Ep 2 | Step 3000 | Train Loss: 0.025952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3487076461.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Summary: Train Loss: 1.314845 | Val Loss: 0.140568 | Time: 331.9s\n",
            "IMPROVEMENT! (0.141900 -> 0.140568)\n",
            "Saved Best Model to /content/sr_model_best.pth\n",
            "   Ep 3 | Step 0 | Train Loss: 0.032289\n",
            "   Ep 3 | Step 500 | Train Loss: 0.029011\n",
            "   Ep 3 | Step 1000 | Train Loss: 0.031858\n",
            "   Ep 3 | Step 1500 | Train Loss: 0.035489\n",
            "   Ep 3 | Step 2000 | Train Loss: 0.028573\n",
            "   Ep 3 | Step 2500 | Train Loss: 0.029507\n",
            "   Ep 3 | Step 3000 | Train Loss: 0.025605\n",
            "Epoch 3 Summary: Train Loss: 1.271869 | Val Loss: 0.140124 | Time: 332.0s\n",
            "IMPROVEMENT! (0.140568 -> 0.140124)\n",
            "Saved Best Model to /content/sr_model_best.pth\n",
            "   Ep 4 | Step 0 | Train Loss: 0.031374\n",
            "   Ep 4 | Step 500 | Train Loss: 0.028719\n",
            "   Ep 4 | Step 1000 | Train Loss: 0.030734\n",
            "   Ep 4 | Step 1500 | Train Loss: 0.034709\n",
            "   Ep 4 | Step 2000 | Train Loss: 0.028236\n",
            "   Ep 4 | Step 2500 | Train Loss: 0.029040\n",
            "   Ep 4 | Step 3000 | Train Loss: 0.025241\n",
            "Epoch 4 Summary: Train Loss: 1.250782 | Val Loss: 0.139158 | Time: 333.1s\n",
            "IMPROVEMENT! (0.140124 -> 0.139158)\n",
            "Saved Best Model to /content/sr_model_best.pth\n",
            "   Ep 5 | Step 0 | Train Loss: 0.030541\n",
            "   Ep 5 | Step 500 | Train Loss: 0.028466\n",
            "   Ep 5 | Step 1000 | Train Loss: 0.030288\n",
            "   Ep 5 | Step 1500 | Train Loss: 0.034314\n",
            "   Ep 5 | Step 2000 | Train Loss: 0.027970\n",
            "   Ep 5 | Step 2500 | Train Loss: 0.028745\n",
            "   Ep 5 | Step 3000 | Train Loss: 0.024974\n",
            "Epoch 5 Summary: Train Loss: 1.230868 | Val Loss: 0.138415 | Time: 333.1s\n",
            "IMPROVEMENT! (0.139158 -> 0.138415)\n",
            "Saved Best Model to /content/sr_model_best.pth\n",
            "   Ep 6 | Step 0 | Train Loss: 0.030318\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3487076461.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    train_count = 0\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    for i, (lr, hr) in enumerate(train_loader):\n",
        "        lr, hr = lr.to(device), hr.to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(lr)\n",
        "            loss = criterion(outputs, hr)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        train_lossi.append(loss.item())\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "        train_count += 1\n",
        "\n",
        "        if i % 500 == 0:\n",
        "            print(f\"   Ep {epoch+1} | Step {i} | Train Loss: {loss.item():.6f}\")\n",
        "\n",
        "    avg_train_loss = running_train_loss / train_count\n",
        "\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    val_count = 0\n",
        "\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "        for val_lr, val_hr in val_loader:\n",
        "            val_lr, val_hr = val_lr.to(device), val_hr.to(device)\n",
        "            val_outputs = model(val_lr)\n",
        "            v_loss = criterion(val_outputs, val_hr)\n",
        "            running_val_loss += v_loss.item()\n",
        "            val_count += 1\n",
        "\n",
        "    avg_val_loss = running_val_loss / val_count\n",
        "    val_lossi.append(avg_val_loss)\n",
        "    scheduler.step(avg_val_loss)\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Summary: Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f} | Time: {epoch_time:.1f}s\")\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        print(f\"IMPROVEMENT! ({best_val_loss:.6f} -> {avg_val_loss:.6f})\")\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        save_file = f\"/content/sr_model_best.pth\"\n",
        "        torch.save(model.state_dict(), save_file)\n",
        "        print(f\"Saved Best Model to {save_file}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"No Improvement. (Best Val was: {best_val_loss:.6f})\")\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f\"EARLY STOPPING TRIGGERED\")\n",
        "            break\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRd7oSSVtuoj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}